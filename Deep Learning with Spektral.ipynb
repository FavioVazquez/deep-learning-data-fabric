{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning with Spektral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#If this worked, you're good to go :)\n",
    "import spektral"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normally you will do something like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But now you need to create a graph representation for your data. The library comes with three datasets: citation, qm9 and delaunay. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spektral.datasets import citation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cora dataset\n"
     ]
    }
   ],
   "source": [
    "adj, node_features, edge_features, _, _, _, _, _ = citation.load_data('cora', val_size=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you see a `ValueError` fix it wiht:\n",
    "\n",
    "```\n",
    "mkdir /home/matrix/.spektral\n",
    "mkdir datasets\n",
    "mkdir/cora\n",
    "cd .spektral/datasets/cora\n",
    "git clone https://github.com/tkipf/gcn.git\n",
    "mv gcn/gcn/data/ .\n",
    "cd data\n",
    "mv * ../\n",
    "rm -r gcn\n",
    "rm -r data\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2708, 2708)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2708, 1433)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2708, 7)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see this is single mode, where we consider a single graph, with its topology and attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Semisupervised classification with Graph Attention layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "from keras.callbacks import EarlyStopping, TensorBoard, ModelCheckpoint\n",
    "from keras.layers import Input, Dropout\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import l2\n",
    "\n",
    "from spektral.datasets import citation\n",
    "from spektral.layers import GraphAttention\n",
    "from spektral.utils.logging import init_logging\n",
    "from spektral.utils.misc import add_eye"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cora dataset\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "dataset = 'cora'\n",
    "adj, node_features, y_train, y_val, y_test, train_mask, val_mask, test_mask = citation.load_data(dataset, val_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "N = node_features.shape[0]    # Number of nodes in the graph\n",
    "F = node_features.shape[1]    # Original feature dimensionality\n",
    "n_classes = y_train.shape[1]  # Number of classes\n",
    "gat_channels = 8              # Output size of first GraphAttention layer\n",
    "n_attn_heads = 8              # Number of attention heads in first GAT layer\n",
    "dropout_rate = 0.6            # Dropout rate applied to the input of GAT layers\n",
    "l2_reg = 5e-4/2               # Regularization rate for l2\n",
    "learning_rate = 5e-3          # Learning rate for SGD\n",
    "epochs = 1                    # Number of epochs to train for (increase if you have more power, 1 will do nothing)\n",
    "es_patience = 100             # Patience fot early stopping\n",
    "log_dir = init_logging()      # Create log directory and file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing operations\n",
    "node_features = citation.preprocess_features(node_features)\n",
    "adj = add_eye(adj).toarray()  # Add self-loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model definition\n",
    "X_in = Input(shape=(F, ))\n",
    "A_in = Input(shape=(N, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model creation\n",
    "dropout_1 = Dropout(dropout_rate)(X_in)\n",
    "graph_attention_1 = GraphAttention(gat_channels,\n",
    "                                   attn_heads=n_attn_heads,\n",
    "                                   attn_heads_reduction='concat',\n",
    "                                   dropout_rate=dropout_rate,\n",
    "                                   activation='elu',\n",
    "                                   kernel_regularizer=l2(l2_reg),\n",
    "                                   attn_kernel_regularizer=l2(l2_reg))([dropout_1, A_in])\n",
    "dropout_2 = Dropout(dropout_rate)(graph_attention_1)\n",
    "graph_attention_2 = GraphAttention(n_classes,\n",
    "                                   attn_heads=1,\n",
    "                                   attn_heads_reduction='average',\n",
    "                                   dropout_rate=dropout_rate,\n",
    "                                   activation='softmax',\n",
    "                                   kernel_regularizer=l2(l2_reg),\n",
    "                                   attn_kernel_regularizer=l2(l2_reg))([dropout_2, A_in])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 1433)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 1433)         0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 2708)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "graph_attention_1 (GraphAttenti (None, 64)           91904       dropout_1[0][0]                  \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_18 (Dropout)            (None, 64)           0           graph_attention_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "graph_attention_2 (GraphAttenti (None, 7)            469         dropout_18[0][0]                 \n",
      "                                                                 input_2[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 92,373\n",
      "Trainable params: 92,373\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build model\n",
    "model = Model(inputs=[X_in, A_in], outputs=graph_attention_2)\n",
    "optimizer = Adam(lr=learning_rate)\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss='categorical_crossentropy',\n",
    "              weighted_metrics=['acc'])\n",
    "model.summary()\n",
    "\n",
    "# Callbacks\n",
    "es_callback = EarlyStopping(monitor='val_weighted_acc', patience=es_patience)\n",
    "tb_callback = TensorBoard(log_dir=log_dir, batch_size=N)\n",
    "mc_callback = ModelCheckpoint(log_dir + 'best_model.h5',\n",
    "                              monitor='val_weighted_acc',\n",
    "                              save_best_only=True,\n",
    "                              save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2708 samples, validate on 2708 samples\n",
      "Epoch 1/1\n",
      "2708/2708 [==============================] - 25s 9ms/step - loss: 1.9946 - weighted_acc: 0.1571 - val_loss: 1.9819 - val_weighted_acc: 0.2000\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "validation_data = ([node_features, adj], y_val, val_mask)\n",
    "model.fit([node_features, adj],\n",
    "          y_train,\n",
    "          sample_weight=train_mask,\n",
    "          epochs=epochs,\n",
    "          batch_size=N,\n",
    "          validation_data=validation_data,\n",
    "          shuffle=False,  # Shuffling data means shuffling the whole graph\n",
    "          callbacks=[es_callback, tb_callback, mc_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model\n",
    "model.load_weights(log_dir + 'best_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model\n",
    "print('Evaluating model.')\n",
    "eval_results = model.evaluate([node_features, adj],\n",
    "                              y_test,\n",
    "                              sample_weight=test_mask,\n",
    "                              batch_size=N)\n",
    "print('Done.\\n'\n",
    "      'Test loss: {}\\n'\n",
    "      'Test accuracy: {}'.format(*eval_results))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
